# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oEupIVsj90M1K47faXpZlEWF8RI8pxBV
"""

!pip install prettytable -q

import pandas as pd
import numpy as np
from prettytable import PrettyTable
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_predict
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, PolynomialFeatures, FunctionTransformer
from sklearn.decomposition import PCA
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, BayesianRidge, SGDRegressor
from sklearn.svm import LinearSVR
import warnings
from sklearn.exceptions import ConvergenceWarning

# =========================
# SUPPRESS CONVERGENCE WARNINGS
# =========================
warnings.filterwarnings("ignore", category=ConvergenceWarning)

# =========================
# 1. LOAD DATA
# =========================
df = pd.read_csv("ML-CUP25-TS.csv", comment="#", header=None)
X = df.iloc[:, :-1]
y = df.iloc[:, -1]

print(f"Dataset: {X.shape[0]} samples, {X.shape[1]} features.\n")

# =========================
# 2. TRAIN/TEST SPLIT
# =========================
Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.25, random_state=42)
print(f"Train: {Xtrain.shape}, Test: {Xtest.shape}\n")

# =========================
# 3. BASELINE MODELS
# =========================
baseline_models = {
    "LinearRegression": LinearRegression(),
    "Ridge": Ridge(),
    "Lasso": Lasso(max_iter=5000),
    "ElasticNet": ElasticNet(max_iter=5000),
    "BayesianRidge": BayesianRidge(),
    "SGDRegressor": SGDRegressor(max_iter=5000),
    "LinearSVR": LinearSVR(max_iter=10000, tol=1e-4)
}

def mean_euclidean_error(y_true, y_pred):
    return np.mean(np.abs(y_true - y_pred))

baseline_results = []

for name, model in baseline_models.items():
    pipe = Pipeline([
        ("scaler", StandardScaler()),
        ("model", model)
    ])
    pipe.fit(Xtrain, ytrain)
    pred_train = pipe.predict(Xtrain)
    pred_test = pipe.predict(Xtest)
    pred_val = cross_val_predict(pipe, Xtrain, ytrain, cv=5)

    baseline_results.append({
        "Model": name,
        "R2_Train": round(r2_score(ytrain, pred_train), 4),
        "R2_Validation": round(r2_score(ytrain, pred_val), 4),
        "R2_Test": round(r2_score(ytest, pred_test), 4),
        "Mean_Euclidean_Error": round(mean_euclidean_error(ytest, pred_test), 4),
        "RMSE": round(np.sqrt(mean_squared_error(ytest, pred_test)), 4)
    })

# Print baseline table
baseline_table = PrettyTable()
baseline_table.field_names = ["Model", "R2_Train", "R2_Validation", "R2_Test", "Mean_Euclidean_Error", "RMSE"]

for row in sorted(baseline_results, key=lambda x: x["R2_Test"], reverse=True):
    baseline_table.add_row([row["Model"], row["R2_Train"], row["R2_Validation"], row["R2_Test"],
                            row["Mean_Euclidean_Error"], row["RMSE"]])

print("=== Baseline Models with TRAIN / VALIDATION / TEST RÂ² ===")
print(baseline_table, "\n")

# =========================
# 4. NONLINEAR TRANSFORMATION FUNCTION
# =========================
def nonlinear_transform(X):
    # Convert to NumPy array to ensure consistent indexing
    X_new = np.array(X, dtype=float)
    for i in range(X_new.shape[1]):
        if np.all(X_new[:, i] >= 0):
            X_new[:, i] = np.log1p(X_new[:, i])
        # Optional: other nonlinear transformations
        # X_new[:, i] = np.sqrt(X_new[:, i])
        # X_new[:, i] = 1 / (X_new[:, i] + 1e-6)
    return X_new

nonlinear_tf = FunctionTransformer(nonlinear_transform, validate=False)

# =========================
# 5. TRANSFORMATIONS + GRID SEARCH
# =========================
transformations = {
    "StandardScaler": ("scaler", StandardScaler()),
    "RobustScaler": ("scaler", RobustScaler()),
    "MinMaxScaler": ("scaler", MinMaxScaler()),
    "Poly2": ("poly", PolynomialFeatures(2, include_bias=False)),
    "Poly3": ("poly", PolynomialFeatures(3, include_bias=False)),
    "Interactions": ("poly", PolynomialFeatures(2, include_bias=False, interaction_only=True)),
    "PCA10": ("pca", PCA(n_components=min(10, X.shape[1]))),
    "Nonlinear": ("nonlinear", nonlinear_tf)
}

param_grids = {
    "Ridge": {"model__alpha": [0.1, 1.0, 10.0]},
    "Lasso": {"model__alpha": [0.01, 0.05, 0.1, 1.0]},
    "ElasticNet": {"model__alpha": [0.01, 0.1, 1.0], "model__l1_ratio": [0.1, 0.5, 0.9]},
    "SGDRegressor": {"model__alpha": [0.0001, 0.001, 0.01]},
    "LinearSVR": {"model__C": [0.1, 1, 10]}
}

improvements = []

for model_name, model in baseline_models.items():
    baseline_r2_test = next(row["R2_Test"] for row in baseline_results if row["Model"] == model_name)

    for tf_name, (step_name, transformer) in transformations.items():
        steps = []
        # Nonlinear transformations go first
        if step_name == "nonlinear":
            steps.append((step_name, transformer))
            steps.append(("scaler", StandardScaler()))
        elif isinstance(transformer, PolynomialFeatures):
            steps.append((step_name, transformer))
            steps.append(("scaler", StandardScaler()))
        elif isinstance(transformer, PCA):
            steps.append(("scaler", StandardScaler()))
            steps.append((step_name, transformer))
        else:
            steps.append((step_name, transformer))
        steps.append(("model", model))

        pipe = Pipeline(steps)
        params = param_grids.get(model_name, {})
        gs = GridSearchCV(pipe, params, cv=5, scoring="r2", n_jobs=-1)
        gs.fit(Xtrain, ytrain)

        pred_train = gs.predict(Xtrain)
        pred_val = cross_val_predict(gs.best_estimator_, Xtrain, ytrain, cv=5)
        pred_test = gs.predict(Xtest)

        r2_train = r2_score(ytrain, pred_train)
        r2_val = r2_score(ytrain, pred_val)
        r2_test = r2_score(ytest, pred_test)
        me_error = mean_euclidean_error(ytest, pred_test)
        rmse = np.sqrt(mean_squared_error(ytest, pred_test))

        if r2_test > baseline_r2_test:
            improvements.append({
                "Model": model_name,
                "Transformation": tf_name,
                "R2_Train": round(r2_train, 4),
                "R2_Validation": round(r2_val, 4),
                "R2_Test": round(r2_test, 4),
                "Mean_Euclidean_Error": round(me_error, 4),
                "RMSE": round(rmse, 4),
                "Gain": round(r2_test - baseline_r2_test, 6)
            })

# Print improvements table
if improvements:
    improvement_table = PrettyTable()
    improvement_table.field_names = ["Model", "Transformation", "R2_Train", "R2_Validation", "R2_Test",
                                     "Mean_Euclidean_Error", "RMSE", "Gain"]

    for row in sorted(improvements, key=lambda x: x["Gain"], reverse=True):
        improvement_table.add_row([row["Model"], row["Transformation"], row["R2_Train"], row["R2_Validation"],
                                   row["R2_Test"], row["Mean_Euclidean_Error"], row["RMSE"], row["Gain"]])

    print("=== Models Improved After Transformation + GridSearch ===")
    print(improvement_table)
else:
    print("No models improved after transformations.")